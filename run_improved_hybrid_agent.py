"""
Run Improved Hybrid Trading Agent
Executes the trained hybrid ML-DRL agent for live trading
"""

import numpy as np
import pandas as pd
from stable_baselines3 import PPO
from improved_hybrid_env import ImprovedHybridTradingEnv
import os
import time
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

def is_market_open():
    """Check if forex market is currently open"""
    now = datetime.now()
    day_of_week = now.weekday()
    hour = now.hour
    
    if day_of_week == 5 and hour >= 22:
        return False
    elif day_of_week == 6:
        return False
    elif day_of_week == 0 and hour < 22:
        return False
    
    return True

def run_improved_hybrid_agent(demo_mode=False, episodes=10):
    """Run the trained hybrid agent"""
    
    print("ğŸ¤– Improved Hybrid Trading Agent")
    print("=" * 50)
    
    if not demo_mode:
        if not is_market_open():
            print("âš ï¸  FOREX MARKET IS CURRENTLY CLOSED")
            print("ğŸ“… Best trading times:")
            print("   â€¢ Monday 00:00 GMT (Sydney open)")
            print("   â€¢ Monday 08:00 GMT (London open)")
            print("   â€¢ Monday 13:00 GMT (New York open)")
            print("\nğŸ® Running in DEMO mode with historical data...")
            demo_mode = True
        else:
            print("âœ… Forex market is OPEN - Ready for live trading!")
    
    # Load the trained model
    model_path = "models/improved_hybrid_trading_agent"
    
    if not os.path.exists(f"{model_path}.zip"):
        print(f"âŒ Trained model not found at {model_path}.zip")
        print("ğŸ”§ Please run 'python train_improved_hybrid_agent.py' first")
        return
    
    print(f"ğŸ“¦ Loading trained model from {model_path}...")
    model = PPO.load(model_path)
    print("âœ… Model loaded successfully!")
    
    # Create environment
    print("ğŸ—ï¸ Creating trading environment...")
    env = ImprovedHybridTradingEnv(
        window_size=24,
        use_ml_signals=True,
        ml_feedback=True,
        max_episode_steps=500
    )
    
    print("ğŸ“Š Environment Details:")
    print(f"   â€¢ Trading pairs: {env.pairs}")
    print(f"   â€¢ Data length: {env.length} timesteps")
    print(f"   â€¢ Episode length: {env.max_episode_steps} steps")
    print(f"   â€¢ ML signals: {env.use_ml_signals}")
    
    # Run trading episodes
    print(f"\nğŸš€ Running {episodes} trading episodes...")
    print("-" * 60)
    
    episode_rewards = []
    total_trades = 0
    
    for episode in range(episodes):
        obs, info = env.reset()
        episode_reward = 0
        episode_trades = 0
        done = False
        step = 0
        
        print(f"\nğŸ“ˆ Episode {episode + 1}/{episodes}")
        print("   Step | Actions | Reward  | Positions | MTM P&L")
        print("   -----|---------|---------|-----------|--------")
        
        while not done and step < env.max_episode_steps:
            # Get agent action
            action, _ = model.predict(obs, deterministic=True)
            
            # Take step
            obs, reward, done, truncated, info = env.step(action)
            episode_reward += reward
            
            # Count trades (position changes)
            if any(info['positions'] != 0):
                episode_trades += 1
            
            # Display progress every 50 steps
            if step % 50 == 0:
                actions_str = ['Hold', 'Buy', 'Sell']
                action_names = [actions_str[a] for a in action]
                
                print(f"   {step:4d} | {str(action_names)[:7]} | {reward:7.2f} | {info['positions']} | {info['mtm_pnl']:6.2f}")
            
            step += 1
            
            if not demo_mode:
                time.sleep(0.1)  # Small delay for live trading
        
        episode_rewards.append(episode_reward)
        total_trades += episode_trades
        
        print(f"\n   ğŸ’° Episode {episode + 1} Summary:")
        print(f"      â€¢ Total reward: {episode_reward:.2f}")
        print(f"      â€¢ Steps taken: {step}")
        print(f"      â€¢ Trades made: {episode_trades}")
        print(f"      â€¢ Final positions: {info['positions']}")
    
    # Overall summary
    print("\n" + "=" * 60)
    print("ğŸ“Š TRADING SESSION SUMMARY")
    print("=" * 60)
    print(f"Total episodes: {episodes}")
    print(f"Average reward: {np.mean(episode_rewards):.2f}")
    print(f"Best episode: {max(episode_rewards):.2f}")
    print(f"Worst episode: {min(episode_rewards):.2f}")
    print(f"Total trades: {total_trades}")
    print(f"Win rate: {len([r for r in episode_rewards if r > 0]) / episodes * 100:.1f}%")
    
    if demo_mode:
        print("\nğŸ® Demo mode completed using historical data")
        print("ğŸš€ For live trading, run during market hours!")
    else:
        print("\nâœ… Live trading session completed")
        print("ğŸ“ˆ Monitor your broker account for actual P&L")
    
    return episode_rewards

def main():
    """Main function"""
    import argparse
    
    parser = argparse.ArgumentParser(description='Run Improved Hybrid Trading Agent')
    parser.add_argument('--demo', action='store_true', help='Run in demo mode')
    parser.add_argument('--episodes', type=int, default=5, help='Number of episodes to run')
    
    args = parser.parse_args()
    
    try:
        rewards = run_improved_hybrid_agent(demo_mode=args.demo, episodes=args.episodes)
        print("\nğŸ‰ Trading session completed successfully!")
        
    except KeyboardInterrupt:
        print("\nâ¹ï¸ Trading stopped by user")
    except Exception as e:
        print(f"\nâŒ Error during trading: {e}")

if __name__ == "__main__":
    main()
